#!/usr/bin/env python
import rospy
from sensor_msgs.msg import Image
import cv2 as cv
import torch
import verification.object_tracking_node.utils as utils
import verification.object_tracking_node.constants as constants
from std_msgs.msg import Float64MultiArray
import cv_bridge
import math
import numpy as np
import geometry_msgs.msg
import tf.transformations
import time
import rospkg
import random
import matplotlib.pyplot as plt
import statistics
from verification.object_tracking_node.image_processing import prepare_image
device = "cuda" if torch.cuda.is_available() else "cpu"
rospack = rospkg.RosPack()

yolo_model = torch.jit.load(rospack.get_path('f1tenth_verification') + "/models/object_detection/yolo.pt")
yolo_model.to(device)

pose_model = torch.jit.load(rospack.get_path('f1tenth_verification') + "/models/object_detection/pose.pt")
pose_model.to(device)


bridge = cv_bridge.CvBridge()
image_pub = rospy.Publisher("test_bounding_boxes",Image)
pose_pub = rospy.Publisher("car_local_pointer",geometry_msgs.msg.PoseArray)

def image_callback(data):
    with torch.no_grad():
        # rospy.loginfo("Test")
        cv_image = bridge.imgmsg_to_cv2(data,desired_encoding='rgb8')
        # For YOLO
        resized_yolo_image = cv.resize(cv_image,(constants.yolo_width_of_image,constants.yolo_height_of_image))
        yolo_tensor = torch.from_numpy(resized_yolo_image).to(device).unsqueeze(0).permute(0,3,1,2).to(torch.float).mul(1/256)
        network_prediction = yolo_model(yolo_tensor)
        bounding_boxes = utils.get_bounding_boxes_for_prediction(network_prediction)
        # # Publishing Local Map
        # pose_array = geometry_msgs.msg.PoseArray()
        # pose_array.poses = []
        # pose_topic_model = geometry_msgs.msg.Pose()
        # point_topic_model = geometry_msgs.msg.Point()
        # point_topic_model.x = 0
        # point_topic_model.y = 0
        # pose_topic_model.position = point_topic_model
        # pose_array.poses.append(pose_topic_model)

        for bounding_box in bounding_boxes:
            prepare_image(cv_image)
            
            pose_topic_model = geometry_msgs.msg.Pose()
            point_topic_model = geometry_msgs.msg.Point()
            point_topic_model.x = 0
            point_topic_model.y = 0
            orientation_model = geometry_msgs.msg.Quaternion()
            quaternion = tf.transformations.quaternion_from_euler(0, 0, yaw)
            orientation_model.w = quaternion[3]
            orientation_model.x = quaternion[0]
            orientation_model.y = quaternion[1]
            orientation_model.z = quaternion[2]
            pose_topic_model.orientation = orientation_model
            pose_topic_model.position = point_topic_model
            pose_array.poses.append(pose_topic_model)

        pose_array.header.frame_id = 'map'
        pose_pub.publish(pose_array)

    image_pub.publish(bridge.cv2_to_imgmsg(cv_image, "rgb8"))

def find_location_of_car(image, x_min,x_max,y_min,y_max):
    resize_x_min = x_min / constants.original_width_image * constants.pose_network_width
    resize_x_max = x_max / constants.original_width_image * constants.pose_network_width
    resize_y_min = y_min / constants.original_height_image * constants.pose_network_height
    resize_y_max = y_max / constants.original_height_image * constants.pose_network_height
    cropped_image = image
    cropped_image[0:int(resize_y_min), :] = 0
    cropped_image[int(resize_y_max):, :] = 0
    cropped_image[:, 0:int(resize_x_min)] = 0
    cropped_image[:, int(resize_x_max):] = 0
    prediction = pose_model(cropped_image.unsqueeze(0).unsqueeze(0))
    x = prediction[0][0]
    y = prediction[0][1]
    return x,y

def setup():
    rospy.init_node('object_tracker')
    pose_publisher = rospy.Publisher(constants.pose_publish_topic,Float64MultiArray,queue_size=10)
    rospy.Subscriber(constants.camera_topic, Image, image_callback,callback_args=(pose_publisher))
    rospy.spin()

if __name__ == '__main__':
    setup()
